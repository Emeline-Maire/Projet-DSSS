{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from bs4) (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (1.26.7)\n",
      "Requirement already satisfied: selenium in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from selenium) (0.19.0)\n",
      "Requirement already satisfied: idna>=2.0.0; extra == \"secure\" in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2.10)\n",
      "Requirement already satisfied: certifi; extra == \"secure\" in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2020.6.20)\n",
      "Requirement already satisfied: cryptography>=1.3.4; extra == \"secure\" in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2.9.2)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14; extra == \"secure\" in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (19.1.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
      "Requirement already satisfied: async-generator>=1.10 in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.14; os_name == \"nt\" and implementation_name != \"pypy\" in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from trio~=0.17->selenium) (1.14.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from trio~=0.17->selenium) (2.2.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from trio~=0.17->selenium) (19.3.0)\n",
      "Requirement already satisfied: six>=1.4.1 in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from cryptography>=1.3.4; extra == \"secure\"->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\antoi\\onedrive\\documents\\lib\\site-packages (from cffi>=1.14; os_name == \"nt\" and implementation_name != \"pypy\"->trio~=0.17->selenium) (2.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install urllib3\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import selenium\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib import request\n",
    "import requests\n",
    "import time\n",
    "from functools import reduce\n",
    "import sys \n",
    "import webbrowser\n",
    "import requests \n",
    "import csv\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création des listes de liens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "liste_pages_tgpreop = []\n",
    "for i in range(300) : \n",
    "  o = i+1\n",
    "  liste_pages_tgpreop.append('https://www.theeroticreview.com'  + f'/reviews/newreviewsList.asp?Valid=1&mp=0&SortBy=3&searchreview=1&Transsexual=2&gDistance=0&page={o}')\n",
    "#liste_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_pages_tgpostop = []\n",
    "for i in range(14) : \n",
    "  o = i+1\n",
    "  liste_pages_tgpostop.append('https://www.theeroticreview.com'  + f'/reviews/newreviewsList.asp?searchreview=1&Transsexual=3&SortBy=3&gDistance&page={o}')\n",
    "#liste_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_pages_cs = []\n",
    "for i in range(9000) : \n",
    "  o = i+1\n",
    "  liste_pages_cs.append('https://www.theeroticreview.com'  + f'/reviews/newreviewsList.asp?searchreview=1&Transsexual=1&SortBy=3&gDistance=0&page={o}')\n",
    "#liste_pages_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_pages=  liste_pages_tgpostop+  liste_pages_tgpreop #+liste_pages_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = {}\n",
    "request_text = {}\n",
    "tableau_participants = {}\n",
    "links = []\n",
    "for i in range(len(liste_pages)) :\n",
    "  request_text[i] = urllib.request.urlopen(liste_pages[i]).read()\n",
    "  page[i] = BeautifulSoup(request_text[i], \"lxml\")\n",
    "  tableau_participants[i] = page[i].find('div',{'class' : \"ter-table\"})\n",
    "  #print(tableau_participants[i])\n",
    "  \n",
    "  for link in tableau_participants[i].findAll('a'):\n",
    "   links.append(link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "link=[]\n",
    "for i in range(len(links)):\n",
    "    link.append('https://www.theeroticreview.com' + links[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "link=pd.DataFrame({'1':link})\n",
    "link.to_csv('link.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "link=[]\n",
    "for i in range(len(links)):\n",
    "    link.append('https://www.theeroticreview.com' + links[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des fonctions de créations de DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_funccol4(tableau_va4) :\n",
    "  tbl = tableau_va4.find_all('div', {\"class\" : \"profile-cost-container-reversed-td profile-cost-container-reversed-td-h col-xs-12\"})\n",
    "  tbl1 = []\n",
    "  for i in range(len(tbl)) :\n",
    "    tbl1.append(tbl[i].get_text())\n",
    "  df4a = pd.DataFrame({'':tbl1})\n",
    "  df4a = df4a.T\n",
    "  df4a['ID'] = 'ID'\n",
    "\n",
    "  tblb = tableau_va4.find_all('div', {\"class\" : \"profile-cost-container-reversed-td col-xs-12\"})\n",
    "  tblb1 = []\n",
    "  for i in range(len(tblb)) :\n",
    "    tblb1.append(tblb[i].get_text())\n",
    "  df4ab = pd.DataFrame({'':tblb1})\n",
    "  df4ab = df4ab.T\n",
    "  df4ab['ID'] = 1\n",
    "\n",
    "\n",
    "  df = pd.concat([df4a, df4ab], ignore_index=False)\n",
    "\n",
    "  new_header = df.iloc[0] #grab the first row for the header\n",
    "  df = df[1:] #take the data less the header row\n",
    "  df.columns = new_header \n",
    "\n",
    "  return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(tableau_va1) : \n",
    "  tbl = tableau_va1.find_all(\"div\",{\"class\":\"profile-table-td profile-table-td-h col-xs-6\"})\n",
    " ### Là je fais ce qu'on a déjà pu faire avant, j'ai selectionné qu'une partie\n",
    " ### du code HTML. Là c'est la partie \"question\" des informations qui sont présentes\n",
    " ### sur le site\n",
    "  tbl1 = [] ### là on fait une petite liste vide \n",
    "\n",
    "  for i in range(len(tbl)) :\n",
    "    tbl1.append(tbl[i].get_text()) ### la fondtion get_text récupère les string au\n",
    "    ### milieu des balises et donc ça c'est vraiment super \n",
    "    ### à la fin dans tbl1 on a une liste qui contient toutes les informations qu'on veut\n",
    "\n",
    "  \n",
    "  df = pd.DataFrame({'':tbl1})\n",
    "  df = df.T\n",
    "  df['ID'] = 'ID'\n",
    "  ### transformation de la liste en DataFrame + ajout de la colonne ID \n",
    "  \n",
    "  tbla = tableau_va1.find_all(\"div\",{\"class\":\"profile-table-td col-xs-6\"})\n",
    "  tbl2 = []\n",
    "  for i in range(len(tbl)) :\n",
    "    tbl2.append(tbla[i].get_text())\n",
    "  tbl2\n",
    "\n",
    "  ff2 = pd.DataFrame({})\n",
    "  df2 = pd.DataFrame({'1':tbl2})\n",
    "  df2 = df2.T\n",
    "  df2['ID'] = 1\n",
    "\n",
    "  df = pd.concat([df, df2], ignore_index=False)\n",
    "\n",
    "  new_header = df.iloc[0] #grab the first row for the header\n",
    "  df = df[1:] #take the data less the header row\n",
    "  df.columns = new_header \n",
    "\n",
    "  return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"collapse1\", \"collapse2\", \"collapse3\"]\n",
    "def my_2func(page):\n",
    "  di = {}\n",
    "  d = {}\n",
    "  l_merge = []\n",
    "  dfc4 = page.find('div', id = 'collapse4')\n",
    "  dfc4 = my_funccol4(dfc4)\n",
    "  l_merge.append(dfc4)\n",
    "  for name in a:\n",
    "    d[name] = page.find('div',id = name) ### là on a bien trois listes \n",
    "    ###d['collapse1'], d['collapse2'], d['collapse3']\n",
    "    di[name] = my_func(d[name])\n",
    "    l_merge.append(di[name])\n",
    "  df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['ID'],\n",
    "                                            how='outer'), l_merge)\n",
    "  return(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [\"collapse4\"]\n",
    "def my_2funckk(page):\n",
    "  di = {}\n",
    "  d = {}\n",
    "  l_merge = []\n",
    "  for name in b :\n",
    "    d[name] = page.find('div',id = name)\n",
    "    di[name] = my_func(d[name])\n",
    "    l_merge.append(di[name])\n",
    "  df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['ID'],\n",
    "                                            how='outer'), l_merge)\n",
    "  return(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Récupération des cookies et headers (à faire à chaque connexion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies = {\n",
    "    '_ga': 'GA1.2.1472492008.1636970512',\n",
    "    'terAgreementVer': '1',\n",
    "    'TERLocationResolved': '1',\n",
    "    'TerTzOffset': '60',\n",
    "    'TER%5FSearchGeoCityId': '',\n",
    "    'TER%5FSearchGeoCityName': '',\n",
    "    'cookieconsent_status': 'dismiss',\n",
    "    'TER%5FSearchCountry': '',\n",
    "    'TER%5FSearchCity': '',\n",
    "    'language': 'en',\n",
    "    'TER%5FRememberPW': '1',\n",
    "    'TER%5FtestCookie': '',\n",
    "    'TER%5Fusername': 'scrapptertable',\n",
    "    'tz': 'Romance+Standard+Time',\n",
    "    'MsTerVer': '6',\n",
    "    'MPA3': '1',\n",
    "    'K-GUID-pocpghie': '3F8CF11C54151A7BCB8706E92E026E87',\n",
    "    '_gid': 'GA1.2.226639742.1644671558',\n",
    "    'TER%5Fsplash': '1',\n",
    "    'TER%5Fhash': 'gWHXPeR%2BG22m8LQbrP6pu3MNVG%2FmOsbQpaSLOJboF0GBwZNI0k%2FxeoyDakeCc8%2F8VZz436W7byfUA9fukLxZTA%3D%3D',\n",
    "    'MsTerCounter': '3',\n",
    "    'GUID': '80A890DE20A23041AE58F8133FB3EC5B',\n",
    "    '_gat': '1',\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'authority': 'www.theeroticreview.com',\n",
    "    'cache-control': 'max-age=0',\n",
    "    'sec-ch-ua': '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"98\", \"Google Chrome\";v=\"98\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.82 Safari/537.36',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'sec-fetch-site': 'none',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'accept-language': 'fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-214-cd1276c5f062>:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm(range(len(link))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0caf8acc9f7b4958bcd4fac938d054a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4710.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "da = {}\n",
    "frames = []\n",
    "for i in tqdm(range(len(link))):\n",
    "  URL = link[i]\n",
    "  request_text = requests.get(URL, headers=headers, cookies=cookies)\n",
    "  page = BeautifulSoup(request_text.text, 'lxml')\n",
    "  da[i] = my_2func(page)\n",
    "  da[i] = da[i].loc[:,~da[i].columns.duplicated()]\n",
    "  #print(da[i])\n",
    "  frames.append(da[i])\n",
    "  #print(frames)\n",
    "  df = pd.concat(frames, ignore_index=True)\n",
    "df.to_csv('df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
